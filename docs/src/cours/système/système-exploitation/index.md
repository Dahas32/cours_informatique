---
layout: layout/post.njk

title: Système d'exploitation

eleventyComputed:
  eleventyNavigation:
    key: "{{ page.url }}"
    title: "{{ title | safe }}"
    parent: "{{ '../' | siteUrl(page.url) }}"
---

Le but d'un [ordinateur](https://fr.wikipedia.org/wiki/Ordinateur) est d'exécuter des [processus](https://fr.wikipedia.org/wiki/Processus_(informatique)). Pour que chaque processus n'ait pas à tout gérer (accès au processeur, à la mémoire, au disque dur, au réseau, ...) comme on le ferait avec un circuit imprimé par exemple, on utilise un [système d'exploitation](https://fr.wikipedia.org/wiki/Syst%C3%A8me_d%27exploitation) (ou ***OS*** pour *operating system*).

Son but est de faire le lien entre le [matériel](https://fr.wikipedia.org/wiki/Mat%C3%A9riel_informatique) (*hardware*) et le [logiciel](https://fr.wikipedia.org/wiki/Logiciel) (*software*).

![os](./os.png)

Le matériel comporte tous les éléments physique d'une machine :

- processeur
- mémoire
- disques dur
- clavier, souris, écran
- carte réseau
- ...

Que l'on peut regrouper en trois grandes catégories :

- processeur
- mémoire
- les [périphériques](https://en.wikipedia.org/wiki/Peripheral) ou *devices* qui regroupent tout le reste. C'est ce qui se branche sur la [carte mère](https://fr.wikipedia.org/wiki/Carte_m%C3%A8re).

Les logiciels, que d'un point de vue système on appellera [process](https://fr.wikipedia.org/wiki/Processus_(informatique)) ou processus auront besoin pour fonctionner d'accéder :

- au processeur pour effectuer les différentes opérations de leur code,
- à la mémoire pour stocker leurs variables
- souvent à des devices comme un disque dur (pour lire un fichiers), à la carte réseau (pour aller lire le contenu du site [hacker news](https://news.ycombinator.com/)), en encore au clavier

{% note %}
Le but d'un système d'exploitation est double :

- il doit permettre d'utiliser les devices de l'ordinateur grâce à des [drivers](https://fr.wikipedia.org/wiki/Pilote_informatique)
- il permet l'exécution de process :
  - de façon [concurrente](https://fr.wikipedia.org/wiki/Programmation_concurrente) (on peut écrire dans un gdoc tout en écoutant de la musique)
  - de façon sécurisée : le gdoc ne peut accéder aux variables de l'application jouant de la musique

{% endnote %}
{% info %}
[Parallèle vs concurrent](https://www.youtube.com/watch?v=r2__Rw8vu1M) :

- concurrent : le début d'un process est entre la début et la fin de l'autre
- parallèle : en même temps
{% endinfo %}

## Couches Systèmes

Un système d’exploitation n'est pas monolithique, il est constitué de multiple partie qui forment un tout cohérent.

L'organisation logicielle d'un ordinateur (ou plus généralement tout système logiciel assez important) est constitué de *couches*, comme le stipule le

{% note "**[théorème fondamental de l’ingénierie logicielle](https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering)**" %}

On peut régler tous les problèmes en ajoutant une couche d'indirection

{% endnote %}

```
       compliqué
A --------------------> B
   simple      simple
A --------> C --------> B
```

Un autre exemple célèbre de couches en ingénierie système est le découpage en [couches d'un réseau](https://fr.wikipedia.org/wiki/Suite_des_protocoles_Internet). Ce principe universel est une instanciation de la [deuxième partie du discours de la méthode](https://fr.wikipedia.org/wiki/Discours_de_la_m%C3%A9thode#Deuxi%C3%A8me_partie) : il faut diviser chaque difficulté en autant de parties facile à résoudre séparément.
D'un point de vue ingénierie, ceci permet en plus de  clairement les responsabilités de chaque couche, une maintenance plus aisée.

Un ordinateur et son utilisation peut être séparé quatre couches :

1. Matériel
   - mémoire RAM
   - devices
2. Noyau
   - drivers matériels
   - gestion de la mémoire
   - ordonnancement des processus
3. process
   - interface graphique
   - terminal
   - ...
4. utilisateurs
   - qui à le droit de faire quoi

Les utilisateurs lancent les process. Ceux-ci s'exécutent de façon parallèle grâce au noyau et utilisent les ressources matériels via des [appels systèmes](https://fr.wikipedia.org/wiki/Appel_syst%C3%A8me).

## Mémoire

{% aller %}
[Mémoire](./mémoire){.interne}
{% endaller %}

## Système d'exploitation

Seul le noyau a accès au matériel et a un contrôle total de la machine. Il doit donc être le plus petit possible car le moindre bug fait planter la machine. C'est pourquoi on distingue deux états d'une machine :

- le *kernel mode* : le noyau travail
- le *user mode* : un process travaille

{% lien %}
[User et Kernel mode sous windows 11](https://learn.microsoft.com/fr-fr/windows-hardware/drivers/gettingstarted/user-mode-and-kernel-mode)
{% endlien %}

Un système d'exploitation ne peut donc être uniquement composé d'un noyau, ce serait inefficace (rien ne pourrait être exécuté en parallèle) et dangereux (le moindre bug logiciel ou matériel ferait tout planter). On sépare habituellement un système d'exploitation en 3 parties :

- **le** [noyau](https://fr.wikipedia.org/wiki/Noyau_de_syst%C3%A8me_d%27exploitation) (*kernel*) dont le but est de gérer :
  - les appels systèmes
  - l'ordonnancement des process
  - communications entre les 3 entités d'un ordinateur (process, matériel, noyau)
- **des** [interfaces logicielles](https://en.wikipedia.org/wiki/Interface_(computing)#Software_interfaces) qui permettent d'accéder aux devices (comme accéder à une clé usb)
- **des** [démons](https://fr.wikipedia.org/wiki/Daemon_(informatique)) qui gèrent l'environnement (le fait de réagir à l'insertion d'une clé usb dans l'ordinateur par exemple)

Les démons et les interfaces sont des process comme les autres. Ils sont cependant exécutés par un utilisateur spécial, souvent nommé [`root`](https://fr.wikipedia.org/wiki/Utilisateur_root), qui est le [super-utilisateur] qui est le représentant utilisateur du système.

![os 2](./os-2.png)

## Utilisateurs

On peut séparer les utilisateurs d'un système en trois grandes catégorie.

### `root`

L'utilisateur `root` est l'utilisateur lié au système d'exploitation. Il est le propriétaire des process (démons) et interfaces du système d'exploitation. Cet utilisateur a ainsi tous les droits (peut aller partout, réserver autant de mémoire qu'il veut, etc).

Comme **Tout** processus a un propriétaire, l'existence de cet utilisateur est garantie.

### Administrateurs systèmes

{% lien %}
[administrateur système](https://fr.wikipedia.org/wiki/Administrateur_syst%C3%A8me)
{% endlien %}

Ces utilisateurs ont des droits particulier, ils peuvent modifier des paramètres systèmes et exécuter ou stopper des démons. Ces utilisateur ne sont pas forcément root, en effet,  souvent l'utilisateur principal d'une machine est administrateur.

Cela permet, si nécessaire, d'installer ou de configurer son système sans être connecté en tant que root.

### Simple utilisateur

Enfin, il existe la foule des autres utilisateurs (vous sur les ordinateurs de l'école ou la fac par exemple) qui ne peuvent pas administer la machine, ni lancer de démons. Vous avez en revanche le droit d'exécuter la plupart des process et d'installer vos propres programme dans l'espace disque qui vous est réservé.

## Process

Un process est l'unité de base d'un programme. Un process est un ensemble d'instruction exécutées par le système d'exploitation. Tout process est la propriété le l'utilisateur du système qui l'a exécuté.

{% aller %}
[Process](./process){.interne}
{% endaller %}

## Noyau

Le noyau est partie intégrante de tout process. Il est toujours là et s'exécute de temps en temps pour effectuer ses tâches.

{% aller %}
[Noyau](./noyau){.interne}
{% endaller %}

## Multi Process

Les systèmes d'exploitation permettent tous d'exécuter plusieurs threads de façon concurrente :

- plusieurs thread d'un même process : ils partagent la même organisation en mémoire
- plusieurs thread de process différents : chaque process à sa propre organisation en mémoire

Ceci peut se passer même si l'ordinateur ne possède qu'un seul core. La quasi totalité des ordinateurs actuellement sont [multi-core](https://fr.wikipedia.org/wiki/Symmetric_multiprocessing), ce qui permet même d'exécuter des threads de façon parallèle.

Chaque thread sur une machine peut–être dans 3 états distincts :

- bloqué : en attente d'une instruction d'entrée/sortie par exemple
- actif : en cours d'exécution
- prêt : prêt à être exécuté

Le principe du multi-processing est est simple. Prenons l'exemple de 2 threads (A et B) à exécuter sur un unique core.
Lorsque le noyau lance l'exécution du premier thread, il va demander au processeur de se faire réveiller au bout de 10ms par une interruption. Le thread A s'exécute donc pendant 10ms avant qu'une interruption ne rappelle le noyau qui va pouvoir stopper le thread A (qu'il va placer en mode activable) et réactiver le thread B (il passe de activable à activé). Une fois ceci fait, le noyau se rendort pour 10ms (via une interruption) et le cycle continue.

Si l'ordinateur possède plusieurs core, le noyau choisi sur quel lancer le thread mais le principe est le même : il se réveille à intervalles déterminés pour gérer l'activation et la désactivation des threads.

Cette activation/ désactivation s'appelle le context switching et n'est pas immédiate, il faut en effet s'assurer que le thread B n'endommage pas l'exécution du thread A.

### Context switching

L'exécution d'un thread dépend :

- de sa mémoire
- des registres du processeur (IP, SP, et tous les autres)

- deux thread d'un même process partagent toute la mémoire sauf la pile,
- deux process différents ne partagent pas la même mémoire sauf le noyau,

Passer d'un thread à l'autre revient donc à :

- sauver les registres de l'un et restaurer ceux de l'autre
- sauver la mémoire de l'un et restaurer la mémoire de l'autre

S'il est facile de sauver/restaurer des registres, ce n'est pas la même chose de la mémoire. Il est illusoire de vouloir sauver toute la mémoire d'un process pour restaurer la mémoire de l'autre process, cela prendrait bien trop de temps.

L'idée est de faire croire au thread qu'il est tout seul en mémoire alors qu'en vrai il la partage avec d'autres.

Pour cela, on commence par découper toute la mémoire en [pages](https://en.wikipedia.org/wiki/Page_table) (habituellement de 4KiB) et d'avoir une correspondance entre une mémoire logique, celle que voit le thread et la mémoire physique, en RAM.

Comme habituellement un thread n'utilise pas toute la mémoire (loin de là même), la mémoire de plusieurs threads peut tenir dans la mémoire physique sans se gêner :

```
mémoire physique  thread A    thread B      segments
      a              a           a           noyau
      b              f           b           pile
      c                          
      d
      e
      f              c           c           bibliothèque partagée
      g          
      h              h           g           data
      i              i           j           code
      j
```

Passer de la mémoire d'un thread à un autre se fait juste en changeant l'adressage, pas physiquement la mémoire.

{% info %}
Lorsque la mémoire RAM physique ne suffit plus pour stocker toutes les données de tous les process, le système d’exploitation possède une partie spécifique du disque dur appelée [swap](https://fr.wikipedia.org/wiki/Espace_d%27%C3%A9change) qui permet de transférer de la RAM au disque dur et réciproquement si nécessaire.
{% endinfo %}

Changer de contexte, et donc d'exécution d'un thread est quelque chose qui va très vite.

### Ordonnancement

Si on doit exécuter $n$ thread sur $p < n$ cores il faut :

- choisir sur quel core exécuter chaque thread
- choisir quel thread exécuter
- choisir le temps pendant lequel exécuter chaque thread

#### Core et thread

Chaque thread possède le code du noyau. Le noyau est donc présent sur chaque core et chaque thread est exécuté par un core :
chaque core possède une liste de thread à exécuter.

De temps en temps, le noyau peut décider de [changer un thread de core](https://www.halolinux.us/kernel-architecture/the-migration-thread.html) pour que la charge d'exécution soit répartie entre tous les cores.

Choisir quel thread exécuter sur quel core pour minimiser le temps total d'exécution est un problème difficile, le noyau a donc des heuristiques de choix simples pour pouvoir décider souvent plutôt qu'optimalement.

{% info %}
Le problème dérive du problème [partition](https://fr.wikipedia.org/wiki/Probl%C3%A8me_de_partition) qui est un problème NP-complet,  (c'est à dire universel) : on ne connaît pas d'autre algorithme que de tester toutes les possibilités.

Pour s'en convaincre, prenons une machine à 2 cores et $n$ processus dont on connaît les temps d'exécution. Minimiser le temps d'exécution des $n$ process revient à séparer les $n$ en deux groupe dont la somme des temps d'exécution est égale.

{% endinfo %}

#### Réactivation d'un thread

Plusieurs possibilités existent, chacune avec leurs avantages et inconvénient :

- chacun son tour. Principe du [tourniquet (round-robin)](https://fr.wikipedia.org/wiki/Round-robin_(informatique))
- par priorité :
  - celui qui a été le moins de temps exécuté : utilisé par la méthode actuelle, [Completely fair scheduler](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler)
  - le premier à finir (utilisé par la nouvelle méthode, [EEVDF](https://en.wikipedia.org/wiki/Earliest_eligible_virtual_deadline_first_scheduling))
  - ...

Pour choisir quel thread activer en premier rapidement, la méthode actuelle d'ordonnancement utilise [un arbre de recherche rouge-noir](https://fr.wikipedia.org/wiki/Arbre_bicolore). Une fois le thread activé, son temps total d'exécution est augmenté (voir [ce document](https://www.geeksforgeeks.org/completely-fair-scheduler-cfs-and-brain-fuck-scheduler-bfs/)) et il est repositionné dans l'arbre.

L'utilisation d'un arbre de recherche rouge-noir garanti que  que l'accès, la modification et l'ajout de threads se fait en $\mathcal{O}(\log(n))$.

#### Temps d'activation

{% lien %}
<https://opensource.com/article/19/2/fair-scheduling-linux>
{% endlien %}

L'algorithme utilisé actuellement (CFS) procède ainsi. Dans un temps donné T, s'il y a $N$ thread à exécuter, on allouera $T/N$ temps à tout le monde.

On s'assure en plus que ce temps est supérieur au temps nécessaire pour le context switching, ce qui assure que tout thread pourra au moins être exécuté 1 cycle.

### Création et fin de process

> TBD : à étoffer.
> séparer ce qui est Linux de la technique générale
>
> <http://books.gigatux.nl/mirror/kerneldevelopment/0672327201/ch03lev1sec2.html>
> clone + copy on write
> <https://www.tutorialspoint.com/unix_system_calls/clone.htm>
> 

Les process sont organisé en arbre. Chaque process ayant un parent, à part le premier process exécuté par le noyau dont le but est de créer tous les démons et de finir par le process de login.

Créer un process se fait à partir du process parent qui est cloné en un nouveau process, l'enfant, qui va partager des caractéristiques avec son parent (en particulier certaines adresses logiques).

Lorsque le process parent se termine (ou est tué par un signal) il commence par terminer ses enfants (en leur envoyant un signal de fin).

## Démarrage de l'ordinateur

Les différentes étapes du chargement d'un système d'exploitation

1. boot de l'ordinateur
2. exécution d'un [chargeur d'amorçage (*bootloader*)](https://fr.wikipedia.org/wiki/Chargeur_d%27amor%C3%A7age)
3. charge le noyau
   1. vérification du matériel
   2. vérification des sous-systèmes : réseau, ...
4. passage en user mode puis charge les démons et les interfaces
5. login
