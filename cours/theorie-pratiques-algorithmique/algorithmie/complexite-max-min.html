<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Complexité max/min | cours d’informatique</title>
<meta name="generator" content="Jekyll v4.2.0">
<meta property="og:title" content="Complexité max/min">
<meta name="author" content="François Brucker">
<meta property="og:locale" content="en_US">
<meta name="description" content="Support de cours/td d’informatique à l’école centrale marseille.">
<meta property="og:description" content="Support de cours/td d’informatique à l’école centrale marseille.">
<link rel="canonical" href="/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/complexite-max-min.html">
<meta property="og:url" content="/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/complexite-max-min.html">
<meta property="og:site_name" content="cours d’informatique">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Complexité max/min">
<script type="application/ld+json">
{"description":"Support de cours/td d’informatique à l’école centrale marseille.","headline":"Complexité max/min","@type":"WebPage","url":"/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/complexite-max-min.html","author":{"@type":"Person","name":"François Brucker"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/cours_informatique/assets/main.css">

  <link rel="stylesheet" href="/cours_informatique/assets/custom.css">
<link type="application/atom+xml" rel="alternate" href="/cours_informatique/feed.xml" title="cours d'informatique">
<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
<header class="site-header" role="banner">

  <div class="wrapper">
<a class="site-title" rel="author" href="/cours_informatique/">cours d'informatique</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger">
            <a class="page-link" href="/cours_informatique/about"> about </a>
        </div>
      </nav>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Complexité max/min</h1>Auteur : <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">François Brucker</span></span>
  </header>

  <div class="post-content">
    <blockquote class="chemin">
  <p><a href="/cours_informatique/cours/theorie-pratiques-algorithmique/">Théorie et pratiques algorithmique</a> / <a href="/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/">algorithmie</a> / <a href="/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/complexite-max-min.html">complexité max/min</a></p>

  <p>prérequis :</p>

  <ul>
    <li><a href="/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/pseudo-code.html">algorithmie/pseudo-code</a></li>
  </ul>
</blockquote>

<p>Où l’on se donne des outils pour mesurer (théoriquement et en pratique) les performances d’un algorithmes</p>

<h2 id="mesures-en-mathcalo">mesures en $\mathcal{O}$</h2>

<p>Mesurer les performances d’un algorithme se fera presque exclusivement en utilisant des $\mathcal{O}$ (<em>grand O</em>)</p>

<blockquote class="note">
  <p>Une fonction $f(N)$ est en $\mathcal{O}(f’(N))$ s’il existe 2 constantes $c_0$ et $N_0$ tels que $f(N) &lt; c_0 \cdot f’(N)$ pour tout $N &gt; N_0$.</p>
</blockquote>

<p>Cela permet :</p>

<ul>
  <li>d’avoir un majorant de notre mesure lorsque $N$ devient grand</li>
  <li>de ne pas s’occuper des constantes puisque (on va le démontrer) une fonction en $\mathcal{O}(\mbox{constante})$ est également en $\mathcal{O}(1)$</li>
  <li>de ne pas s’occuper de la proportionnalité car (on va le démontrer) une fonction en $\mathcal{O}(\mbox{constante} \cdot f(N))$ est également en $\mathcal{O}(f(N))$</li>
</ul>

<blockquote class="note">
  <p>Connaitre le comportement en $\mathcal{O}$ d’une mesure dépendant de $N$ nous donne un majorant de son comportement lorsque $N$ devient grand. Si le majorant n’est pas trop éloigné de la mesure originale, cela nous donne une <strong>idée générale</strong> de la valeur de la mesure lorsque $N$ devient grand.</p>
</blockquote>

<p>Ceci est plutôt intéressant en algorithmie car l’on ne connait pas toujours exactement le nombre d’opérations élémentaires utilisées, mais on peut les majorer de façon assez précise. On utilisera ainsi les $\mathcal{O}$ pour mesurer :</p>

<ul>
  <li>le nombre d’opérations élémentaires effectuée par l’algorithme avant de s’arrêter</li>
  <li>le temps mis par l’algorithme pour s’exécuter</li>
  <li>la taille de la mémoire utilisée pour par l’algorithme</li>
</ul>

<p>Par rapport à la taille $N$ de l’entrée de l’algorithme.</p>

<h3 id="arithmétique-des-mathcalo">arithmétique des $\mathcal{O}$</h3>

<p>Par abus de langage, on notera :</p>

<ul>
  <li>$\mathcal{O}(f(N))$ plutôt que soit $f’(N)$ une fonction en $\mathcal{O}(f(N))$</li>
  <li>$f(N) = \mathcal{O}(g(N))$ plutôt que : “la fonction $f(N)$ est en $\mathcal{O}(g(N))$”</li>
  <li>$\mathcal{O}(f(N)) \Rightarrow \mathcal{O}(g(N))$ plutôt que “une fonction en $\mathcal{O}(f(N))$ est également en $\mathcal{O}(g(N))$”</li>
  <li>$\mathcal{O}(f(N)) \Leftrightarrow \mathcal{O}(g(N))$ plutôt que “une fonction en $\mathcal{O}(f(N))$ est également en $\mathcal{O}(g(N))$ et réciproquement”</li>
</ul>

<blockquote class="note">
  <p>On a les règles suivantes :</p>

  <ol>
    <li>$\mathcal{O}(A) \Leftrightarrow \mathcal{O}(1)$, avec $A$ une contante strictement positive</li>
    <li>$\mathcal{O}(N^p) \Rightarrow \mathcal{O}(N^q)$ pour $q \geq p$</li>
    <li>$f(N) = \mathcal{O}(g(N))$ implique $\mathcal{O}(f(N) + g(N) + h(N)) \Rightarrow \mathcal{O}(g(N) + h(N))$</li>
    <li>$f(N) = \mathcal{O}(g(N))$ implique $\mathcal{O}(f(N) \cdot g(N) \cdot h(N) + h’(N)) \Rightarrow \mathcal{O}((g(N))^2 \cdot h(N)+ h’(N))$</li>
  </ol>

  <p>Et en combinant les $\mathcal{O}$ pour $f$ et $g$ deux fonction positives :</p>

  <ul>
    <li>$\mathcal{O}(f(N)) + \mathcal{O}(g(N)) \Rightarrow \mathcal{O}(f(N) + g(N))$</li>
    <li>$\mathcal{O}(f(N)) \cdot \mathcal{O}(g(N)) \Rightarrow \mathcal{O}(f(N) \cdot g(N))$</li>
  </ul>

</blockquote>

<blockquote class="a-faire">
  <p>Démontrez ces propriétés.</p>
</blockquote>

<details><summary>Démonstration de $\mathcal{O}(A) \Leftrightarrow \mathcal{O}(1)$, avec $A$ une contante strictement positive</summary><div>
<p>Soit $f(N) = \mathcal{O}(A)$. Il existe donc $c_0$ et $N_0$ tels que pour tout $N &gt; N_0$, on ait $f(N) &lt; c_0 \cdot A$. En posant $c’_0 = c_0 \cdot A$, on a $f(N) &lt; c’_0 \cdot 1$ pour tout $N &gt; N_0$ donc $f(N) = \mathcal{O}(1)$.</p>

<p>Réciproquement, soit $f(N) = \mathcal{O}(1)$. Il existe donc $c_0$ et $N_0$ tels que pour tout $N &gt; N_0$, on ait $f(N) &lt; c_0 \cdot 1$. En posant $c’_0 = c_0 / A$, on a $f(N) &lt; c’_0 \cdot A$ pour tout $N &gt; N_0$ donc $f(N) = \mathcal{O}(A)$.</p>

</div></details>

<details><summary>Démonstration de $\mathcal{O}(N^p) \Rightarrow \mathcal{O}(N^q)$ pour $q \geq p$</summary><div>
<p>Soit $f(N) = \mathcal{O}(N^p)$. Il existe donc $c_0$ et $N_0$ tels que $f(N) &lt; c_0 \cdot N^p$ pour $N &gt; N_0$.
Comme $1 &lt; 2 \cdot N^\alpha$ pour $\alpha \geq 0$ et $N&gt; 1$, on a $N^p &lt; c_0 \cdot N^q$ pour $c_0 = 2$, $N &gt; 1 = N_0$  et $p \leq q$ : $N^p = \mathcal{O}(N^q)$ pour tout $p \leq q$</p>

</div></details>

<details><summary>Démonstration de $f(N) = \mathcal{O}(g(N))$ implique $\mathcal{O}(f(N) + g(N) + h(N)) \Rightarrow \mathcal{O}(g(N) + h(N))$</summary><div>
<p>Soit $f(N) = \mathcal{O}(g(N))$. Il existe donc $c_0$ et $N_0$ tels que $f(N) &lt; c_0 \cdot N^p$ pour $N &gt; N_0$. Si $f’(N) = \mathcal{O}(f(N) + g(N) + h(N))$ il existe $c’_0$ et $N’_0$ tels que $f’(N) &lt; c’_0(f(N) + g(N) + h(N))$ pour $N &gt; N_0$.</p>

<p>De là, $f’(N) &lt; c’_0 c_0 g(N) + c’_0 g(N) + c’_0 h(N)$ pour $N &gt; \max \{ N_0, N’_0 \}$ ce qui implique $f’(N) &lt; \max \{ c’_0, c_0 \}^2 (g(N) + h(N))$ pour $N &gt; \max \{ N_0, N’_0 \}$ : $f’(N) = \mathcal{O}(g(N) + h(N))$</p>

</div></details>

<details><summary>Démonstration de $f(N) = \mathcal{O}(g(N))$ implique $\mathcal{O}(f(N) \cdot g(N) \cdot h(N) + h’(N)) \Rightarrow \mathcal{O}((g(N))^2 \cdot h(N)+ h’(N))$</summary><div>
<p>Soit $f(N) = \mathcal{O}(g(N))$. Il existe donc $c_0$ et $N_0$ tels que $f(N) &lt; c_0 \cdot N^p$ pour $N &gt; N_0$. Si $f’(N) = \mathcal{O}(f(N)\cdot g(N) \cdot h(N) + h’(N))$ il existe $c’_0$ et $N’_0$ tels que $f’(N) &lt; c’_0(f(N) \cdot g(N) \cdot h(N) + h’(N))$ pour $N &gt; N_0$.</p>

<p>De là, $f’(N) &lt; c’_0 (c_0 g(N) \cdot g(N) \cdot h(N) + h’(N)$ pour $N &gt; \max \{ N_0, N’_0 \}$ ce qui implique $f’(N) &lt; \max \{ c’_0, c_0 \}^2 (g(N)^2 \cdot  h(N) + h’(N))$ pour $N &gt; \max \{ N_0, N’_0 \}$ : $f’(N) = \mathcal{O}((g(N))^2 \cdot h(N) + h’(N))$</p>

</div></details>

<details><summary>Démonstration de  $\mathcal{O}(f(N)) + \mathcal{O}(g(N)) \Rightarrow \mathcal{O}(f(N) + g(N))$</summary><div>
<p>Soient $f’(N) = \mathcal{O}(f(N))$ et $g’ = \mathcal{O}(g(N))$, il existe donc $c_0$, $c’_0$, $N_0$ et $N’_0$ tels que $f’(N) &lt; c_0 f(N)$ pour $N &gt; N_0$ et $g’(N) &lt; c’_0 g(N)$ pour $N &gt; N’_0$.</p>

<p>On a alors $f’(N) + g’(N) &lt; \max \{c_0, c’_0\} (f(N) + g(N))$ pour $N &gt; \max \{ N_0, N’_0\}$ : $f’(N) + g’(N) = \mathcal{O}(f(N) + g(N))$.</p>

</div></details>

<details><summary>$\mathcal{O}(f(N)) \cdot \mathcal{O}(g(N)) \Rightarrow \mathcal{O}(f(N) \cdot g(N))$</summary><div>
<p>Soient $f’(N) = \mathcal{O}(f(N))$ et $g’ = \mathcal{O}(g(N))$, il existe donc $c_0$, $c’_0$, $N_0$ et $N’_0$ tels que $f’(N) &lt; c_0 f(N)$ pour $N &gt; N_0$ et $g’(N) &lt; c’_0 g(N)$ pour $N &gt; N’_0$.</p>

<p>On a alors $f’(N) \cdot g’(N) &lt; \max \{c_0, c’_0, 1 \}^2 (f(N) \cdot g(N))$ pour $N &gt; \max \{ N_0, N’_0\}$ car $f$ et $g$ sont positives : $f’(N) \cdot g’(N) = \mathcal{O}(f(N) \cdot g(N))$.</p>

</div></details>

<h3 id="conséquences-algorithmique">conséquences algorithmique</h3>

<p>La règle (1) montre qu’un nombre constant est toujours en $\mathcal{O}(1)$. Pour un algorithme, il est souvent compliqué de savoir exactement de combien d’[opérations basique] basique](/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/pseudo-code.html#instruction-basique) est constitué une opération, ou le temps exact qu’elle va prendre (pour un ordinateur, cela dépend du type de processeur par exemple. L’addition avec un x68 est faites <a href="https://ensiwiki.ensimag.fr/index.php?title=Constructions_de_base_en_assembleur_x86">avec des registres</a> par exemple, et donc l’addition nécessite 2 opération du processeur). Mais on pourra toujours montrer qu’il y en a un nombre constant (ou borné par un nombre constant) :</p>

<blockquote class="note">
  <p>La complexité d’une opération basique nécessite $\mathcal{O}(1)$ opérations.</p>
</blockquote>

<p>De là :</p>

<blockquote class="note">
  <p>un nombre constant d’opérations basiques nécessite $\mathcal{O}(1)$ opérations.</p>
</blockquote>

<p>Les règles précédentes permettent plus généralement de montrer :</p>

<blockquote class="note">
  <p>$\mathcal{O}(A \cdot f(N)) \Leftrightarrow A \cdot \mathcal{O}(f(N)) \Leftrightarrow \mathcal{O}(f(N))$, avec $A$ une contante strictement positive et $f(N)$ une fonction strictement positive pour $N &gt; N_0$</p>
</blockquote>

<p>Ceci est pratique. En reprenant l’exemple de la partie <a href="/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/pseudo-code.html#complexit%C3%A9">complexité des pseudo-code</a>, car cela permet de ne pas compter toutes les opérations basiques précisément :</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = 30
if ((x &gt; 12) AND (y &lt; 36)):
    z = x * "coucou"
</code></pre></div></div>

<ol>
  <li>on affecte un objet à x : 1 instruction, donc $\mathcal{O}(1)$ opérations.</li>
  <li>un test avec 2 comparaisons et un <code class="language-plaintext highlighter-rouge">AND</code> : 3 instructions, donc $\mathcal{O}(3) = \mathcal{O}(1)$ opérations.</li>
  <li>on affecte le résultat d’une opération élémentaire : 2 instructions, donc $\mathcal{O}(2) = \mathcal{O}(1)$ opérations.</li>
</ol>

<p>Un nombre total d’instructions de $3 \mathcal{O}(1) = \mathcal{O}(1)$ opérations.</p>

<p>En revanche, faites attention, cela ne marque que pour les constantes !</p>

<blockquote class="attention">
  <p>Si le nombre d’opérations élémentaires est variable on a : $n \mathcal{O}(1) = \mathcal{O}(n)$ !</p>
</blockquote>

<p>Enfin, comme en algorithmie on manipulera souvent des polynômes, on peut montrer facielement avec les règles précédentes que :</p>

<blockquote class="note">
  <p>\sum_{i=0}^na_i x^i = \mathcal{O}(x^n)</p>
</blockquote>

<h2 id="complexité-dun-algorithme">complexité d’un algorithme</h2>

<p>On l’a vu dans la partie <a href="/cours_informatique/cours/theorie-pratiques-algorithmique/algorithmie/pseudo-code.html#complexit%C3%A9">pseudo-code</a>, la complexité est le nombre d’opérations basiques effectuées par un algorithme. Le nombre d’opérations basiques effectué par un pseudo-code va être dépendant des entrées de celui-ci, même si les entrées ont la même taille (on verra des exemples de ça).</p>

<p>On distinguera trois types de complexités :</p>

<ul>
  <li>nombre d’opérations basiques effectuées</li>
  <li>temps d’exécution d’un programme</li>
  <li>taille mémoire consommée pendant l’exécution</li>
</ul>

<p>Les complexités vont toutes dépendre des entrées, plus précisément d’un paramètre rendant compte de leur <strong>taille</strong>, c’est à dire du nombre de cases mémoires nécessaires pour les stocker.</p>

<h3 id="nombre-dopérations-basiques">nombre d’opérations basiques</h3>

<blockquote class="note">
  <p>La <strong>complexité</strong> (aussi parfois appelée <strong>complexité maximale</strong>) d’un algorithme est le <strong>nombre maximum d’opérations basiques</strong> effectué par celui-ci pour des entrées <em>*de taille totale donnée</em>. Elle sera donnée en $\mathcal{O}(f(N))$, où $N$ est une variable rendant compte de la taille des données.</p>
</blockquote>

<p>La <strong>taille</strong> d’une entrée étant proportionnelle au nombre de cases mémoires que celle-ci nécessite.</p>

<p>Il arrive que certains algorithmes aient un comportement très différent selon les entrées. Parler seulement de la complexité (nombre maximum d’opérations) ne permet pas alors de le caractériser complètement. On pourra alors aussi parler de :</p>

<blockquote class="note">
  <p>La <strong>complexité minimale</strong> d’un algorithme est le <strong>nombre minium d’opérations basiques</strong> effectué par celui-ci pour des entrées <em>*de taille totale donnée</em>. Elle sera donnée en $\mathcal{O}(f(N))$, où $N$ est une variable rendant compte de la taille des données.</p>
</blockquote>

<p>Lorsque l’on calcule une complexité (maximale ou minimale) sous la forme d’un $\mathcal{O}(f(N))$, on tentera bien sur de trouver la fonction $f(N)$ la plus petite possible.</p>

<h3 id="temps-dexécution">temps d’exécution</h3>

<p>Un moyen efficace de mesurer la complexité d’un algorithme écrit sous la forme d’un code exécutable est de mesurer le temps mis pour son exécution pour un jeu d’entrée donné.</p>

<blockquote class="note">
  <p>la <strong>complexité en temps</strong> d’un algorithme est le temps mis pour l’exécuter en utilisant un jeu de donné de taille donnée pour lequel la complexité est atteinte.</p>
</blockquote>

<p>Le temps pris sera bien sur différent si l’on prend une machine plus puissante ou si l’on change le code de l’algorithme mais <strong>complexité en temps sera proportionnelle à la complexité</strong>. Pour le voir, il suffit de mesurer la durée d’exécution de chaque instruction basique et de la borner par le max.</p>

<blockquote class="attention">
  <p>Si vous ne prenez pas un jeu de donné pour lequel la com^plexité de l’algorithme est atteinte, vous ne mesurez <strong>pas</strong> la complexité temporelle de l’algorithme…</p>
</blockquote>

<h3 id="taille-mémoire">taille mémoire</h3>

<blockquote class="note">
  <p>la <strong>complexité en espace</strong> d’un algorithme est le nombre maximum de cases mémoires utilisées pour l’exécuter en utilisant un jeu de donné de taille donnée.</p>
</blockquote>

<p>Comme la complexité, on la mesurera avec des $\mathcal{O}$.</p>

<p>Notez que la complexité en espace n’est pas forcément atteinte pour un jeu de donné donnant la complexité de l’algorithme, mais <strong>complexité en espace sera toujours plus faible que la complexité</strong> (puisque visiter une case mémoire nécessite une opération élémentaire).</p>

<h3 id="complexité-de-fonctions-ou-méthodes">complexité de fonctions ou méthodes</h3>

<blockquote class="attention">
  <p>Toutes les autres opérations doivent être examinée, en particulier les méthodes d’objets qui peuvent prendre plus de temps.</p>
</blockquote>

<blockquote class="tbd">
  <p>Avec python si je dix t.max() pas en O(1)</p>
</blockquote>

<h3 id="exemple-1--quelle-est-la-complexité-de-lalgorithme-suivant">exemple 1 : quelle est la complexité de l’algorithme suivant</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total</span><span class="o">=</span><span class="mi">0</span>
<span class="n">de</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span> <span class="n">à</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="n">faire</span> <span class="p">:</span>
    <span class="n">de</span> <span class="n">j</span><span class="o">=</span><span class="mi">1</span>  <span class="n">à</span> <span class="n">n</span> <span class="n">faire</span> <span class="p">:</span>
		<span class="n">total</span><span class="o">=</span><span class="n">total</span><span class="o">+</span><span class="mi">1</span>
<span class="n">Rendre</span> <span class="n">total</span>
</code></pre></div></div>

<p>Cheminement de l’algorithme :</p>

<ul>
  <li>ligne 1 : une affectation, donc en temps constant, donc $\mathcal{O}(1)$</li>
  <li>ligne 2 : une affectation (<code class="language-plaintext highlighter-rouge">i=1</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 3:  une affectation (<code class="language-plaintext highlighter-rouge">j=1</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 4 : une opération et une affectation, donc $\mathcal{O}(1) + \mathcal{O}(1)$</li>
  <li>ligne 3:  une affectation (<code class="language-plaintext highlighter-rouge">j=2</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 4 : une opération et une affectation, donc $\mathcal{O}(1) + \mathcal{O}(1)$</li>
  <li>…</li>
  <li>ligne 3:  une affectation (<code class="language-plaintext highlighter-rouge">j=n</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 4 : une opération et une affectation, donc $\mathcal{O}(1) + \mathcal{O}(1)$</li>
  <li>ligne 2 : une affectation (<code class="language-plaintext highlighter-rouge">i=2</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 3:  une affectation (<code class="language-plaintext highlighter-rouge">j=1</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 4 : une opération et une affectation, donc $\mathcal{O}(1) + \mathcal{O}(1)$</li>
  <li>…</li>
  <li>ligne 3:  une affectation (<code class="language-plaintext highlighter-rouge">j=n</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 4 : une opération et une affectation, donc $\mathcal{O}(1) + \mathcal{O}(1)$</li>
  <li>…</li>
  <li>ligne 2 : une affectation (<code class="language-plaintext highlighter-rouge">i=n-1</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 3:  une affectation (<code class="language-plaintext highlighter-rouge">j=1</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 4 : une opération et une affectation, donc $\mathcal{O}(1) + \mathcal{O}(1)$</li>
  <li>…</li>
  <li>ligne 3:  une affectation (<code class="language-plaintext highlighter-rouge">j=n</code>) donc en $\mathcal{O}(1)$</li>
  <li>ligne 4 : une opération et une affectation, donc $\mathcal{O}(1) + \mathcal{O}(1)$</li>
  <li>linge 4 : une affectation $\mathcal{O}(1)$</li>
</ul>

<p>On peut rassembler les boucles entres-elles :
Donc l’algorithme :</p>

<ul>
  <li>ligne 1 : une affectation, donc en temps constant, donc $\mathcal{O}(1)$</li>
  <li>ligne 2 : une affectation (de la variable i) donc en $\mathcal{O}(1)$ et un début de bloc qui sera effectué $n-1$ fois, donc de l’ordre de $\mathcal{O}(n)$ fois.</li>
  <li>ligne 3:  une affectation (de la variable j) donc en $\mathcal{O}(1)$ et un début de bloc qui sera effectué $n-1$ fois, donc de l’ordre de $\mathcal{O}(n)$ fois.</li>
  <li>ligne 4 : une affectation, donc en temps constant, donc $\mathcal{O}(1)$</li>
  <li>ligne 5 : une affectation, donc en temps constant, donc $\mathcal{O}(1)$</li>
</ul>

<p>on a donc une complexité de :</p>

\[\mathcal{O}(1) + \mathcal{O}(n) * (\mathcal{O}(1) + \mathcal{O}(n) * (\mathcal{O}(1) + \mathcal{O}(1))) + \mathcal{O}(1)\]

<p>ceci vaut :</p>

\[\mathcal{O}(2) + \mathcal{O}(n) * (\mathcal{O}(1) + \mathcal{O}(n) * \mathcal{O}(2))\]

<p>Comme $\mathcal{O}(2) = \mathcal{O}(1)$ on a : 
\(\mathcal{O}(1) + \mathcal{O}(n) * (\mathcal{O}(1) + \mathcal{O}(n) * \mathcal{O}(1))\)</p>

<p>donc comme $\mathcal{O}(n) * \mathcal{O}(1) = \mathcal{O}(1 * n) = \mathcal{O}(n)$ :</p>

\[\mathcal{O}(1) + \mathcal{O}(n) * (\mathcal{O}(1) + \mathcal{O}(n))\]

<p>Donc : 
\(\mathcal{O}(1) + \mathcal{O}(n) + \mathcal{O}(n^2)\)</p>

<p>Comme \(\mathcal{O}(n^2 + n + 1) = \mathcal{O}(n^2)\)</p>

<p>La complexité finale de l’algorithme est en : $\mathcal{O}(n^2)$</p>

<p><strong>Règle de calcul simple :</strong></p>

<ul>
  <li>on multiplie le nombre de fois où on execute un bloc par la complexité du bloc.</li>
  <li>on peut die qu’une suite d’instruction en $\mathcal{O}(1)$ est également en $\mathcal{O}(1)$</li>
</ul>

<h3 id="exemple-3--quelle-est-la-complexité-de-lalgorithme-suivant">exemple 3 : quelle est la complexité de l’algorithme suivant</h3>

<p>Attention à la deuxième boucle. Est-ce important pour le résultat ?</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>total=0
de i=1 à n-1 faire :
    de j=i+1 à n faire :
        total=total+1
Rendre total
</code></pre></div></div>
<p>On va utiliser une autre règle que l’on va montrer par la pratique :</p>

<blockquote>
  <p>Si une boucle s’exécute un nombre variable de fois, mais que cette variation est croissante (respectivement décroissante), on peut considérer pour le calcul de la complexité qu’elle s’exécute à chaque fois  de l’ordre du maximum de fois.</p>
</blockquote>

<p>Ici, la boucle de la ligne 3 s’exécute un nombre variable de fois qui dépend de la valeur de $i$. Comme $i$ va croitre, le nombre de fois où cette boucle va s’exécuter va décroitre. Donc on peut dire qu’elle va s’exécuter de l’ordre de $\mathcal{O}(n)$ fois, exactement comme pour l’exemple 1.</p>

<p>On peut donc estimer la complexité de l’algorithme à $\mathcal{O}(n^2)$ fois.</p>

<p>On peut faire un calcul exact de la complexité pour vérifier.</p>

<ul>
  <li>ligne 1 : $\mathcal{O}(1)$</li>
  <li>itération pour $i=1$:
    <ul>
      <li>une affectation $i=1$ : $\mathcal{O}(1)$</li>
      <li>boucle pour $j=1$:
  	* une affectation de $j$ :  $\mathcal{O}(1)$
  	* la ligne 4 :  $\mathcal{O}(1)$
  	* le tout $n-1$ fois</li>
    </ul>
  </li>
  <li>itération pour $i=2$:
    <ul>
      <li>une affectation $i=2$ : $\mathcal{O}(1)$</li>
      <li>boucle pour $j=2$:
  	* une affectation de $j$ :  $\mathcal{O}(1)$
  	* la ligne 4 :  $\mathcal{O}(1)$
        <ul>
          <li>le tout $n-2$ fois</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>…</li>
  <li>itération pour $i=n-1$:
    <ul>
      <li>une affectation $i=n-1$ : $\mathcal{O}(1)$</li>
      <li>boucle pour $j=n-1$:
  	* une affectation de $j$ :  $\mathcal{O}(1)$
  	* la ligne 4 :  $\mathcal{O}(1)$
        <ul>
          <li>le tout $1$ fois</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>ligne 5 : $\mathcal{O}(1)$</li>
</ul>

<p>Notre complexité totale est donc :</p>

\[\mathcal{O}(1) + (\mathcal{O}(1) + (n-1) * (\mathcal{O}(1) + \mathcal{O}(1))) + 
(\mathcal{O}(1) + (n-2) * (\mathcal{O}(1) + \mathcal{O}(1))) + \dots
 + (\mathcal{O}(1) + (1) * (\mathcal{O}(1) + \mathcal{O}(1))) + \mathcal{O}(1)\]

<p>comme $\mathcal{O}(1) + \mathcal{O}(1) = \mathcal{O}(1)$, on a :</p>

\[\mathcal{O}(1) + (\mathcal{O}(1) + (n-1) * (\mathcal{O}(1))) + 
(\mathcal{O}(1) + (n-2) * (\mathcal{O}(1))) + \dots
 + (\mathcal{O}(1) + (1) * (\mathcal{O}(1))) + \mathcal{O}(1)\]

\[\mathcal{O}(1) + ((n) * (\mathcal{O}(1))) + 
((n-1) * (\mathcal{O}(1))) + \dots
 + ((2) * (\mathcal{O}(1))) + \mathcal{O}(1)\]

<p>et donc notre complexité vaut : 
\(\mathcal{O}(1) + \sum_{1\leq i \leq n} i * \mathcal{O}(1)\)</p>

<p>comme la somme des n premiers entiers vaut $(n+1)(n)/2$ notre complexité devient : 
\(\mathcal{O}(1) + (n+1)(n)/2 * \mathcal{O}(1)\)</p>

<p>Ce qui est de l’ordre de :</p>

\[\mathcal{O}((n+1)(n)/2) = \mathcal{O}((1/2) * (n^2 +n)) = \mathcal{O}((n^2 +n)) = \mathcal{O}(n^2)\]

<p>On retrouve bien le résultat attendu.</p>

<h3 id="exemple-3--plus-grand-élément-dun-tableau-de-longueur-n">exemple 3 : plus grand élément d’un tableau de longueur $n$.</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">maximum</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">si</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">sinon</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">maximum</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>On vérifie bien que :</p>

<ol>
  <li>l’algorithme converge bien</li>
  <li>il rend bien le maximum d’un tableau</li>
</ol>

<p>La complexité est définie par l’équation de récurrence $C(n) = \mathcal{O}(1) + C(n-1)$ et $C(0) =  \mathcal{O}(1)$</p>

<p>En bornant le temps constant par $K$, on a l’équation de récurrence suivante : $C(N) = K + C(N-1)$</p>

<p>$C(N) = K + K + C(N-2) = \dots = n * K + C(0) = (n+1) * K = \mathcal{O}(n)$</p>

<h1 id="comparaisons-des-complexités">comparaisons des complexités</h1>

<p>Un mauvais choix d’algorithme peut entraîner une différence très importante (facteur 100, 1000, etc.) alors que l’optimisation du code ne fait gagner a priori qu’un facteur 10 au mieux.</p>

<p>Il existe souvent plusieurs algorithme pour résoudre un problème. De temps en temps un algorithme est meilleurs que tous les autres, mais souvent cela dépend du type de données en entrée (on le verra). Il est donc important non seulement de connaître les complexités des algorithmes pour choisir le meilleurs mais également de connaitre son cas d’utilisation.</p>

<h2 id="temps-pour-résoudre-un-problème-de-taille-n">Temps pour résoudre un problème de taille $n$</h2>

<p>Exemple d’évolution du temps de calcul par rapport à la complexité. En supposant, que l’on ait un ordinateur qui résout des problèmes de complexité $n$ en 0.01 ms pour des données de taille 10, on peut remplir le tableau ci-après.</p>

<p>En colonnes le nombre $n$ de données, en lignes les complexités des algorithmes.</p>

<table>
  <thead>
    <tr>
      <th>complexité</th>
      <th>10</th>
      <th>20</th>
      <th>30</th>
      <th>40</th>
      <th>50</th>
      <th>60</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$n$</td>
      <td>0.01 ms</td>
      <td>0.02 ms</td>
      <td>0.03 ms</td>
      <td>0.04 ms</td>
      <td>0.05 ms</td>
      <td>0.06 ms</td>
    </tr>
    <tr>
      <td>$n^2$</td>
      <td>0.1 ms</td>
      <td>0.4 ms</td>
      <td>0.9 ms</td>
      <td>1.6 ms</td>
      <td>2.5 ms</td>
      <td>3.6 ms</td>
    </tr>
    <tr>
      <td>$n^3$</td>
      <td>1 ms</td>
      <td>8 ms</td>
      <td>27 ms</td>
      <td>64 ms</td>
      <td>125 ms</td>
      <td>216 ms</td>
    </tr>
    <tr>
      <td>$n^5$</td>
      <td>1s</td>
      <td>3.2 s</td>
      <td>24.3 s</td>
      <td>1.7 min</td>
      <td>5.2 min</td>
      <td>13 min</td>
    </tr>
    <tr>
      <td>$2^n$</td>
      <td>1 ms</td>
      <td>1s</td>
      <td>17.9 min</td>
      <td>12.7 jours</td>
      <td>35.7 ans</td>
      <td>36600 ans</td>
    </tr>
    <tr>
      <td>$3^n$</td>
      <td>59 ms</td>
      <td>58 min</td>
      <td>6.5 ans</td>
      <td>385500 ans</td>
      <td>2x1010 ans</td>
      <td>13x1016 siècles</td>
    </tr>
  </tbody>
</table>

<p>L’évolution est dramatique plus la complexité augmente. Pour une complexité polynomiale, la croissance est encore maitrisée même s’il vaut mieux avoir une petite complexité pour traiter plus de données. Pour une complexité exponentielle ($2^n$ et $3^n$) la durée est tout simplement rédhibitoire.</p>

<h2 id="nombre-de-problèmes-résolu-par-heure">Nombre de problèmes résolu par heure</h2>

<p>En colonne la rapidité de la machine, en ligne le nombre de problème d’une complexité donné réalisé en 1 heure.</p>

<table>
  <thead>
    <tr>
      <th>complexité</th>
      <th>machine actuelle</th>
      <th>100x plus rapide</th>
      <th>1000x plus rapide</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$n$</td>
      <td>N1</td>
      <td>100xN1</td>
      <td>1000xN1</td>
    </tr>
    <tr>
      <td>$n^2$</td>
      <td>N2</td>
      <td>10xN2</td>
      <td>31.6xN2</td>
    </tr>
    <tr>
      <td>$n^3$</td>
      <td>N3</td>
      <td>4.64xN3</td>
      <td>10xN3</td>
    </tr>
    <tr>
      <td>$n^5$</td>
      <td>N4</td>
      <td>2.5xN4</td>
      <td>3.98xN4</td>
    </tr>
    <tr>
      <td>$2^n$</td>
      <td>N5</td>
      <td>N5+6.64</td>
      <td>N5+9.97</td>
    </tr>
    <tr>
      <td>$3^n$</td>
      <td>N6</td>
      <td>N6+4.19</td>
      <td>N6+6.29</td>
    </tr>
  </tbody>
</table>

<p>La encore, l’évolution est dramatique plus la complexité augmente. Pour des complexité polynomiales le nombre de problème augmente d’un facteur multiplicatif lorsque la vitesse augment, mais ce n’est pas le cas pour des complexités exponentielles. Pour ces problèmes, augmenter la vitesse de la machine ne change pas fondamentalement le nombre de problèmes que l’on peut résoudre.</p>

<h2 id="trouver-un-élément-dans-un-tableauchaîne-de-caractère">trouver un élément dans un tableau/chaîne de caractère.</h2>

<p>On cherche toujours le cas le pire. Dans des algorithmes dont le nombre d’opérations dépend de l’entrée on choisira des entrées maximisant le nombre d’opérations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">est_dans_tableau</span><span class="p">(</span><span class="n">valeur</span><span class="p">,</span> <span class="n">tableau</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tableau</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">valeur</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">True</span>
	<span class="k">return</span> <span class="bp">False</span>
</code></pre></div></div>

<p>Dans l’algorithme ci-dessous la complexité est maximale pour deux cas :</p>

<ul>
  <li>l’élément recherché n’est pas dans le tableau</li>
  <li>l’élément recherché est le dernier élément du tableau</li>
</ul>

<p>Car c’est là que l’on parcourt toute la boucle.</p>

<p>complexité : on parcourt tout le tableau et l’interieur de la boucle est en $\mathcal{O}(1)$. La complexité au pire est donc de $\mathcal{O}(len(\mbox{tableau}))$</p>

<p>On verra dans le cours sur les tris, qu’il existe encore d’autres notions de complexités : la <em>complexité minimale</em> et la <em>complexité en moyenne</em>.</p>

<h2 id="structures">structures</h2>

<blockquote>
  <p><strong>TBD</strong> Exemple du tableau en regardant comment fonctionne la mémoire. Et les complexité de maintien de la structure.</p>
</blockquote>

<p>objet = place dans la mémoire</p>


  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/cours_informatique/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">cours d'informatique</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">cours d'informatique</li>
</ul>
      </div>

      <div class="footer-col footer-col-2">
<ul class="social-media-list"><li><a href="https://github.com/FrancoisBrucker"><svg class="svg-icon"><use xlink:href="/cours_informatique/assets/minima-social-icons.svg#github"></use></svg> <span class="username">FrancoisBrucker</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Support de cours/td d'informatique à l'école centrale marseille.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
